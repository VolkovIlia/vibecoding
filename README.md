# Ansible AI Stack Deployer

Этот Ansible-проект предназначен для автоматического развертывания комплексного стека популярных Open Source AI-инструментов на VPS под управлением Ubuntu 22.04 LTS. Все приложения запускаются в Docker-контейнерах и настраиваются для взаимодействия друг с другом.

## Возможности

*   **Автоматическое развертывание:** Установка и настройка всего стека одной Ansible-командой.
*   **Контейнеризация:** Все сервисы работают в Docker-контейнерах, управляемых через Docker Compose.
*   **Гибкая конфигурация:** Интерактивные запросы при запуске для настройки пользователя, домена, профиля Ollama и других параметров.
*   **HTTPS "из коробки":** Автоматическая настройка HTTPS с помощью Caddy при использовании собственного домена.
*   **Интегрированный стек:** Включает популярные инструменты для локальной работы с LLM, автоматизации, векторного поиска и разработки.

## Включенные приложения

*   [**n8n**](https://n8n.io/): Платформа Low-code автоматизации.
*   [**SearXNG**](https://searxng.org/): Приватная метапоисковая система.
*   [**Flowise**](https://flowiseai.com/): Визуальный конструктор LLM-приложений.
*   [**Supabase**](https://supabase.com/): Open Source альтернатива Firebase (PostgreSQL, Auth, Storage, Realtime и др.).
*   [**Qdrant**](https://qdrant.tech/): Высокопроизводительная векторная база данных.
*   [**Caddy**](https://caddyserver.com/): Современный веб-сервер с автоматическим HTTPS.
*   [**OpenWebUI**](https://openwebui.com/): Веб-интерфейс в стиле ChatGPT для взаимодействия с локальными LLM и агентами n8n.
*   [**Ollama**](https://ollama.com/): Платформа для запуска и управления локальными LLM.
*   [**Langfuse**](https://langfuse.com/): Платформа для LLM-инжиниринга и наблюдаемости (включая PostgreSQL, ClickHouse, MinIO, Redis/Valkey).

## Предварительные требования

### Управляющая машина (где запускается Ansible)

*   **Ansible:** Установленный Ansible (версия 2.10+ рекомендуется). [Инструкция по установке Ansible](https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html).
*   **Git:** Для клонирования этого репозитория.

### Целевой сервер (VPS)

*   **ОС:** Ubuntu 22.04 LTS (чистая установка рекомендуется).
    *   *(Примечание: Целевым сервером может быть как физический VPS у хостинг-провайдера, так и виртуальная машина в облаке (AWS EC2, Google Cloud Compute Engine, Azure VM и т.д.) или на вашем локальном гипервизоре (VMware, Hyper-V, Proxmox), если она соответствует остальным требованиям).*
*   **Доступ:** SSH-доступ к серверу с правами `root` или пользователем с `sudo` без пароля (для первоначального запуска Ansible). Ansible создаст нового пользователя для дальнейшей работы.
*   **Ресурсы:**
    *   **CPU/RAM:** Зависят от используемых моделей Ollama и нагрузки. Рекомендуется минимум 4 CPU / 8-16 GB RAM для комфортной работы с небольшими моделями. Для более крупных моделей и активного использования Supabase/Langfuse потребуется больше ресурсов.
    *   **Диск:** Достаточное количество места для Docker-образов, данных приложений (базы данных, векторные индексы, модели Ollama). Рекомендуется SSD от 50-100 GB и выше.
*   **DNS (Опционально, для HTTPS):** Если вы планируете использовать собственный домен, убедитесь, что A-запись (или AAAA для IPv6) вашего домена (и поддоменов для каждого сервиса, например `n8n.yourdomain.com`, `supabase.yourdomain.com` и т.д.) указывает на IP-адрес вашего VPS. Caddy использует это для автоматического получения SSL-сертификатов Let's Encrypt.

## Установка и Настройка

1.  **Клонировать репозиторий:**
    ```bash
    git clone <URL_вашего_репозитория>
    cd <имя_директории_репозитория>
    ```

2.  **Настроить инвентарный файл:**
    *   Откройте файл `inventory/hosts.ini`.
    *   В секции `[vps_server]` раскомментируйте строку и замените `your_vps_ip_address` на реальный IP-адрес вашего VPS.
    *   Укажите пользователя для подключения Ansible (обычно `root` для первого запуска): `ansible_user=root`.
    *   Пример: `192.0.2.10 ansible_user=root`

3.  **(Рекомендуется) Настроить Ansible Vault для секретов:**
    *   Вместо ввода секретов через интерактивные запросы (которые могут сохраняться в истории команд), рекомендуется использовать [Ansible Vault](https://docs.ansible.com/ansible/latest/user_guide/vault.html) для шифрования чувствительных данных.
    *   Создайте зашифрованный файл переменных (например, `inventory/group_vars/all/vault.yml`) командой `ansible-vault create inventory/group_vars/all/vault.yml`.
    *   Задайте пароль для Vault.
    *   Перенесите определение секретов (пароли, API ключи, JWT секреты) из секции `vars_prompt` файла `playbook.yml` в этот vault-файл.
    *   При запуске плейбука используйте флаг `--ask-vault-pass` или настройте `vault_password_file`.

4.  **Запустить Ansible Playbook:**
    *   Выполните команду из корневой директории проекта:
        ```bash
        ansible-playbook playbook.yml -i inventory/hosts.ini [--ask-vault-pass]
        ```
    *   Ansible подключится к вашему VPS и начнет процесс установки и настройки.

5.  **Ответить на интерактивные запросы:**
    *   Во время выполнения плейбук запросит у вас необходимую информацию:
        *   **Имя пользователя:** Имя нового пользователя, который будет создан на VPS для управления стеком.
        *   **Пароль пользователя:** Пароль для нового пользователя (будет запрошено подтверждение).
        *   **Использовать домен? (yes/no):** Выберите, будете ли вы использовать собственный домен (для HTTPS) или доступ по IP-адресу.
        *   **Основное доменное имя:** Если выбрали "yes", введите ваш основной домен (например, `example.com`). Поддомены будут созданы автоматически (n8n.example.com, supabase.example.com и т.д.).
        *   **Email для Let's Encrypt:** Если используете домен, введите ваш email для регистрации SSL-сертификатов.
        *   **Профиль Ollama (cpu, nvidia, amd):** Выберите профиль в зависимости от наличия GPU на вашем VPS.
        *   **Модели Ollama для загрузки:** Укажите через запятую модели, которые нужно загрузить при первом запуске (например, `qwen2.5:7b-instruct-q4_K_M,nomic-embed-text`). Оставьте пустым, чтобы не загружать.
        *   **Включить бэкапы? (yes/no):** Включить ли автоматическое резервное копирование ( *Функционал в разработке* ).
        *   **Время бэкапа:** Если включено, укажите время для ежедневного бэкапа ( *Функционал в разработке* ).
        *   **Секреты:** Введите все необходимые секреты для n8n, Supabase, Langfuse (если не используете Ansible Vault). **Генерируйте надежные, случайные значения!**

6.  **Дождаться завершения:** Плейбук выполнит все шаги, установит пакеты, настроит Docker, скопирует конфигурации и запустит все контейнеры. Это может занять некоторое время, особенно при первой загрузке Docker-образов и моделей Ollama.

## Тестирование на Локальной Виртуальной Машине (с помощью Vagrant)

Перед развертыванием на реальный VPS, настоятельно рекомендуется протестировать этот Ansible-плейбук на локальной виртуальной машине (ВМ). Это поможет выявить потенциальные проблемы в контролируемой среде. [Vagrant](https://www.vagrantup.com/) является отличным инструментом для этой цели.

**Предварительные требования для локального тестирования:**

*   **Vagrant:** Установите Vagrant с официального сайта.
*   **Провайдер виртуализации:** Установите провайдер, поддерживаемый Vagrant, например:
    *   [VirtualBox](https://www.virtualbox.org/) (бесплатный, наиболее распространенный)
    *   Libvirt/KVM (для Linux)
    *   VMware Workstation/Fusion (платный)

**Шаги для тестирования:**

1.  **Создать `Vagrantfile`:** В корневой директории вашего проекта создайте файл с именем `Vagrantfile`.

2.  **Настроить `Vagrantfile`:** Добавьте в `Vagrantfile` следующую конфигурацию (пример для VirtualBox):

    ```ruby
    # -*- mode: ruby -*-
    # vi: set ft=ruby :

    Vagrant.configure("2") do |config|
      # Используем официальный бокс Ubuntu 22.04 LTS
      config.vm.box = "ubuntu/jammy64"

      # Настройка сети: Private network для доступа с хоста по статическому IP
      config.vm.network "private_network", ip: "192.168.56.110"

      # Настройка провайдера (VirtualBox)
      config.vm.provider "virtualbox" do |vb|
        # Выделите достаточно ресурсов для ВМ
        vb.memory = "8192" # 8 GB RAM (минимум, рекомендуется больше)
        vb.cpus = "4"      # 4 CPU ядра (минимум)
        # vb.customize ["modifyvm", :id, "--natdnshostresolver1", "on"] # Может помочь с DNS
        # vb.customize ["modifyvm", :id, "--natdnsproxy1", "on"]
      end

      # Отключить стандартную синхронизацию папок Vagrant, если не нужна
      # config.vm.synced_folder ".", "/vagrant", disabled: true

      # Настройка Ansible provisioner
      config.vm.provision "ansible" do |ansible|
        ansible.playbook = "playbook.yml"
        ansible.inventory_path = "inventory/hosts_vagrant" # Используем отдельный инвентарный файл для Vagrant
        ansible.become = true # Выполнять задачи с sudo
        ansible.ask_become_pass = false # Пароль sudo не требуется для пользователя vagrant по умолчанию
        ansible.extra_vars = {
          # Здесь можно переопределить переменные или передать секреты
          # Например, чтобы не использовать интерактивные запросы:
          # vps_user_name: "ai_stack_user",
          # vps_user_password: "$6$rounds=656000$...hashed_password...", # Пре-хешированный пароль
          # use_custom_domain: "no", # Для локального теста обычно домен не используется
          # ollama_profile: "cpu",
          # enable_backups: "no",
          # n8n_encryption_key: "your_secret_key_here", # Лучше использовать Vault!
          # ... и другие секреты
        }
        # Если используете Ansible Vault:
        # ansible.ask_vault_pass = true
        # или ansible.vault_password_file = ".vault_pass"
      end
    end
    ```

3.  **Создать инвентарный файл для Vagrant (`inventory/hosts_vagrant`):**
    Vagrant автоматически создаст временный инвентарный файл, но для явного управления лучше создать свой. Создайте файл `inventory/hosts_vagrant` со следующим содержимым:
    ```ini
    [vps_server]
    default ansible_host=127.0.0.1 ansible_port=2222 ansible_user='vagrant' ansible_ssh_private_key_file='.vagrant/machines/default/virtualbox/private_key'

    [all:vars]
    ansible_python_interpreter=/usr/bin/python3
    # Укажите IP-адрес ВМ для доступа к сервисам (если не используете домен)
    # Это значение будет использоваться в шаблонах, где есть ansible_default_ipv4.address
    ansible_default_ipv4={ "address": "192.168.56.110" }
    ```
    *   **Важно:** Путь к `ansible_ssh_private_key_file` может отличаться. Vagrant создаст его при первом `vagrant up`. Убедитесь, что он правильный. Порт `2222` также является стандартным для Vagrant SSH forward.

4.  **Запустить ВМ и провижининг:**
    ```bash
    vagrant up
    ```
    Эта команда скачает образ Ubuntu (если его нет), создаст ВМ, запустит ее и автоматически выполнит Ansible-плейбук (`vagrant provision`). Если вы внесли изменения в плейбук после `vagrant up`, выполните `vagrant provision` для повторного запуска Ansible.

5.  **Тестирование:**
    *   После завершения провижининга, доступ к сервисам будет осуществляться по IP-адресу ВМ (`192.168.56.110` в примере) и портам, указанным в `README.md` для режима "Доступ по IP". Например, n8n будет доступен по `http://192.168.56.110:{{ caddy_n8n_port }}`.
    *   Вы можете подключиться к ВМ по SSH: `vagrant ssh`.
    *   Используйте инструкции из файла `TESTING.md` для проверки сервисов.

6.  **Остановка и удаление ВМ:**
    *   `vagrant halt`: Остановить ВМ.
    *   `vagrant destroy -f`: Удалить ВМ и все связанные с ней ресурсы.

**Примечания:**

*   При тестировании на локальной ВМ выбирайте опцию **"не использовать собственный домен"** при запросе Ansible.
*   Убедитесь, что на вашем хост-компьютере достаточно ресурсов (RAM, CPU, Disk) для запуска ВМ и всех Docker-контейнеров.
*   Передача секретов через `ansible.extra_vars` в `Vagrantfile` **небезопасна**. Для реального использования секретов всегда применяйте Ansible Vault.

## Доступ к Сервисам

После успешного завершения плейбука сервисы будут доступны по следующим адресам (замените `<vps_ip>` на IP вашего сервера и `yourdomain.com` на ваш домен, если используется):

| Сервис          | Доступ с доменом (HTTPS)                | Доступ по IP (HTTP)                               | Внутренний порт (для Caddy) | Примечание                                    |
| --------------- | --------------------------------------- | ------------------------------------------------- | --------------------------- | --------------------------------------------- |
| n8n             | `https://n8n.yourdomain.com`            | `http://<vps_ip>:{{ caddy_n8n_port }}`            | 5678                        |                                               |
| OpenWebUI       | `https://openwebui.yourdomain.com`      | `http://<vps_ip>:{{ caddy_openwebui_port }}`      | 8080                        |                                               |
| Flowise         | `https://flowise.yourdomain.com`        | `http://<vps_ip>:{{ caddy_flowise_port }}`        | 3001                        |                                               |
| Supabase (API)  | `https://supabase.yourdomain.com`       | `http://<vps_ip>:{{ caddy_supabase_port }}`       | 8000 (Kong)                 | Доступ к API и Supabase Studio                |
| SearXNG         | `https://searxng.yourdomain.com`        | `http://<vps_ip>:{{ caddy_searxng_port }}`        | 8080                        |                                               |
| Langfuse        | `https://langfuse.yourdomain.com`       | `http://<vps_ip>:{{ caddy_langfuse_port }}`       | 3000 (Web)                  |                                               |
| Ollama API      | `https://ollama.yourdomain.com` (опц.)  | `http://<vps_ip>:{{ caddy_ollama_port }}` (опц.)  | 11434                       | Обычно не выставляется наружу без защиты      |
| Qdrant API      | -                                       | -                                                 | 6333 (gRPC), 6334 (HTTP)    | Доступен внутри Docker-сети для приложений    |

*   Порты для доступа по IP (`{{ caddy_..._port }}`) определены в `roles/app_stack/defaults/main.yml` и могут быть изменены.
*   **Учетные данные:** Для Supabase Studio и Langfuse могут потребоваться учетные данные, которые вы задали при настройке или которые были сгенерированы (проверьте `.env` файл на сервере или вывод Ansible, если не использовали Vault). Для n8n и OpenWebUI обычно требуется создать пользователя при первом входе.

## Первые шаги

1.  **Войдите в веб-интерфейсы:** Используя адреса из таблицы выше, зайдите в n8n, OpenWebUI, Flowise, Supabase Studio, Langfuse. Создайте пользователей, где это необходимо.
2.  **Настройте OpenWebUI:** Подключите модели Ollama в настройках OpenWebUI.
3.  **Загрузите модели Ollama (если не загрузились автоматически):**
    *   Подключитесь к VPS по SSH.
    *   Выполните: `docker exec ollama ollama pull <имя_модели>` (например, `docker exec ollama ollama pull nomic-embed-text`).
4.  **Изучите сервисы:** Начните создавать workflow в n8n, чат-флоу в Flowise, экспериментируйте с моделями в OpenWebUI, исследуйте возможности Supabase и Langfuse.

## Обслуживание

*   **Проверка статуса:**
    ```bash
    ssh <vps_user>@<vps_ip>
    cd /opt/ai_stack
    docker compose ps
    ```
*   **Просмотр логов:**
    ```bash
    docker logs <имя_контейнера> # например, docker logs n8n
    docker compose logs -f <имя_сервиса> # Следить за логами конкретного сервиса
    ```
*   **Обновление стека:** ( *Функционал в разработке* ) Будет добавлен Ansible-тег или отдельный плейбук для обновления Docker-образов (`docker-compose pull`) и перезапуска стека.
*   **Резервное копирование:** ( *Функционал в разработке* ) Если включено при установке, будет настроено cron-задание для бэкапа Docker-томов. Инструкции по восстановлению будут добавлены.

## Устранение неисправностей

*   **Проверьте логи Docker:** Это первое место для поиска ошибок (`docker logs <имя_контейнера>`).
*   **Проверьте статус контейнеров:** `docker compose ps`. Убедитесь, что все контейнеры запущены.
*   **Проверьте настройки файрвола:** `sudo ufw status`. Убедитесь, что порты 80 и 443 открыты.
*   **Проблемы с DNS/HTTPS:** Если используете домен, убедитесь, что DNS записи настроены правильно и указывают на IP вашего VPS. Проверьте логи Caddy (`docker logs caddy`).
*   **Нехватка ресурсов:** Следите за использованием CPU, RAM и диска на VPS (`htop`, `df -h`).
*   **Обратитесь к `TESTING.md`:** В этом файле есть инструкции по базовой проверке работоспособности сервисов.

## Структура проекта

```
.
├── .gitignore
├── TESTING.md
├── ai_stack_deployment_plan.md # Детальный план разработки (с чек-листом)
├── inventory/
│   └── hosts.ini             # Инвентарный файл (целевые серверы)
├── playbook.yml                # Основной Ansible Playbook
├── roles/
│   ├── app_stack/              # Роль для развертывания Docker стека
│   │   ├── defaults/
│   │   │   └── main.yml        # Переменные по умолчанию для роли
│   │   ├── handlers/
│   │   │   └── main.yml        # Обработчики (например, перезапуск docker-compose)
│   │   ├── tasks/
│   │   │   └── main.yml        # Основные задачи роли app_stack
│   │   └── templates/
│   │       ├── Caddyfile.j2    # Шаблон конфигурации Caddy
│   │       ├── docker-compose.yml.j2 # Шаблон Docker Compose
│   │       ├── dot_env.j2      # Шаблон .env файла (для секретов)
│   │       └── searxng_settings.yml.j2 # Шаблон настроек SearXNG
│   ├── common/                 # Роль для общих настроек сервера
│   │   ├── handlers/
│   │   │   └── main.yml        # Обработчики (например, перезагрузка UFW)
│   │   └── tasks/
│   │       └── main.yml        # Задачи (обновление, пакеты, пользователь, UFW)
│   └── docker/                 # Роль для установки Docker
│       ├── handlers/
│       │   └── main.yml        # Обработчики (перезапуск Docker)
│       └── tasks/
│           └── main.yml        # Задачи (установка Docker Engine, Compose)
└── README.md                   # Этот файл
```

## Лицензия

(Добавьте информацию о лицензии, если необходимо, например, MIT или Apache 2.0)